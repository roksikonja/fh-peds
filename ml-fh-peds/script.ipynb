{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70aafd1-9b40-4ae2-9226-0e18729f426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46126b5a-6b41-4f98-a9ce-7468654cb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "\n",
    "from pathlib import Path\n",
    "from utils import read_data\n",
    "\n",
    "style.use(\"seaborn-v0_8\")\n",
    "\n",
    "RECOMPUTE = True\n",
    "\n",
    "project_dir = Path(\".\")\n",
    "data_dir = project_dir / \"data\"\n",
    "results_dir = project_dir / \"results\"\n",
    "\n",
    "data_slo = read_data(data_dir=data_dir, cohort=\"slo\", version=\"final\", recompute=RECOMPUTE)\n",
    "data_por = read_data(data_dir=data_dir, cohort=\"por\", version=\"final\", recompute=RECOMPUTE)\n",
    "\n",
    "data_raw = pd.concat([data_slo, data_por], axis=0)\n",
    "data_raw.sample(3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73659fe7-fe68-4956-9c95-1c32df9b02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from utils import X_COLUMN_ORDER\n",
    "from utils import COLUMN_ORDER\n",
    "from utils import Y_COLUMN\n",
    "from utils import BINARY_CATEGORICAL_COLUMNS\n",
    "from utils import MULTI_CATEGORICAL_COLUMNS\n",
    "from utils import CLASS_NAMES\n",
    "from utils import impute_and_scale_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4185610-a806-410a-9acc-ad15d032d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scaling_info = impute_and_scale_data(data_raw, mask_predicate=lambda row: row[\"cohort\"] == \"slo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068f7a1-2ebb-4c32-9467-af1192fe0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_model_and_cv\n",
    "from utils import X_COLUMNS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "BASE_MODEL = LogisticRegression(random_state=0, penalty=\"l2\", max_iter=100)\n",
    "PARAM_GRID = {\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"C\": [1 / 128, 1 / 64, 1 / 32, 1 / 16, 1 / 8, 1 / 4, 1.0, 4.0, 16.0, 64.0, 128.0],\n",
    "    \"fit_intercept\": [True, False],\n",
    "}\n",
    "RANDOM_STATE = 3\n",
    "SIZE_TEST_SPLIT = 0.4\n",
    "\n",
    "data[\"split\"] = \"test\"\n",
    "indices_train_val, _ = train_test_split(\n",
    "    data[data[\"cohort\"] == \"slo\"].index,\n",
    "    test_size=SIZE_TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=data[data[\"cohort\"] == \"slo\"][Y_COLUMN],\n",
    ")\n",
    "data.loc[indices_train_val, \"split\"] = \"train_val\"\n",
    "\n",
    "model, df_cv = train_model_and_cv(\n",
    "    model=BASE_MODEL,\n",
    "    param_grid=PARAM_GRID,\n",
    "    X=data[data[\"split\"] == \"train_val\"][X_COLUMNS],\n",
    "    y=data[data[\"split\"] == \"train_val\"][Y_COLUMN],\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228ba94-3c08-4416-9411-9de4a33ea499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "from utils import filter_by_metadata\n",
    "\n",
    "for cohort, version, split in [\n",
    "    (\"slo\", \"final\", \"train_val\"),\n",
    "    (\"slo\", \"final\", \"test\"),\n",
    "    (\"por\", \"final\", \"test\"),\n",
    "]:\n",
    "    print(f\"Split: {split}, '{cohort}', {version}\")\n",
    "    data_subset = filter_by_metadata(data, cohort=cohort, version=version, split=split)\n",
    "    \n",
    "    y_true = data_subset[Y_COLUMN]\n",
    "    y_pred = model.predict(data_subset[X_COLUMNS])\n",
    "    report = classification_report(y_true, y_pred, target_names=CLASS_NAMES)\n",
    "    print(report)\n",
    "\n",
    "    print(\"AUC:\", roc_auc_score(\n",
    "        y_true=data_subset[Y_COLUMN],\n",
    "        y_score=model.predict_proba(data_subset[X_COLUMNS])[:, 1],\n",
    "    ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e847cd4-333b-4917-90b3-3f718e6ba1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from utils import compute_metrics\n",
    "\n",
    "# Sensitivity = TP Rate = Recall = TP / P\n",
    "# Specificity = TN Rate = TN / N\n",
    "\n",
    "metrics = []\n",
    "for t in np.linspace(0.01, 1.00, 100):\n",
    "    recall_pos_slo, recall_neg_slo, precision_pos_slo = compute_metrics(\n",
    "        filter_by_metadata(data, cohort=\"slo\", version=\"final\", split=\"test\"),\n",
    "        model=model,\n",
    "        threshold=t\n",
    "    )\n",
    "\n",
    "    recall_pos_por, recall_neg_por, precision_pos_por = compute_metrics(\n",
    "        filter_by_metadata(data, cohort=\"por\", version=\"final\", split=\"test\"),\n",
    "        model=model,\n",
    "        threshold=t\n",
    "    )\n",
    "\n",
    "    metrics.append({\n",
    "        \"threshold\": t,\n",
    "        # Slovenia\n",
    "        \"specificity (slo/test)\": recall_neg_slo,\n",
    "        \"sensitivity/recall (slo/test)\": recall_pos_slo,\n",
    "        \"precision (slo/test)\": precision_pos_slo,\n",
    "        # Portugal\n",
    "        \"specificity (por/test)\": recall_neg_por,\n",
    "        \"sensitivity/recall (por/test)\": recall_pos_por,\n",
    "        \"precision (por/test)\": precision_pos_por,\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_title(\"Specificity-Sensitivity Curve\")\n",
    "ax.set_xlabel(\"Sensivity\")\n",
    "ax.set_ylabel(\"Specificity\")\n",
    "ax.plot(\n",
    "    metrics_df[\"sensitivity/recall (slo/test)\"],\n",
    "    metrics_df[\"specificity (slo/test)\"],\n",
    "    color=\"tab:green\",\n",
    "    label=\"SLO (Test split)\",\n",
    ")\n",
    "ax.plot(\n",
    "    metrics_df[\"sensitivity/recall (por/test)\"],\n",
    "    metrics_df[\"specificity (por/test)\"],\n",
    "    color=\"tab:red\",\n",
    "    label=\"POR (Test split)\",\n",
    ")\n",
    "plt.legend(loc=\"lower left\")\n",
    "metrics_df.to_excel(results_dir / \"specificity_sensitivity.xlsx\")\n",
    "\n",
    "metrics_df[metrics_df[\"specificity (slo/test)\"] > 0.949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8136e-a2de-4f82-a9d1-3a11182a9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.coef_.shape == (1, len(model.feature_names_in_))\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"feature_name\": model.feature_names_in_,\n",
    "    \"weight\": model.coef_[0],\n",
    "    \n",
    "}).sort_values(\"weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41328292-3bc1-4986-bd62-69e94478e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (data_raw.index == data.index).all()\n",
    "\n",
    "data_raw[\"split\"] = data[\"split\"]\n",
    "data_raw[\"predicted_probability\"] = pd.Series(model.predict_proba(data[X_COLUMNS])[:, 1], index=data.index)\n",
    "data_raw.to_excel(results_dir / \"model_split_probability.xlsx\")\n",
    "data_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba524c15-66f1-45b4-9374-0d5b3f295559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.set_title(\"Precision-Recall Curve\")\n",
    "for cohort, version, split, kwargs in [\n",
    "    (\"slo\", \"final\", \"train_val\", {\"color\": \"tab:green\", \"alpha\": 0.5}),\n",
    "    (\"slo\", \"final\", \"test\", {\"color\": \"tab:green\", \"alpha\": 1.0}),\n",
    "    (\"por\", \"final\", \"test\", {\"color\": \"tab:red\", \"alpha\": 0.5}),    \n",
    "    # (\"slo\", 2.0, \"train_val\", {\"color\": \"tab:green\", \"alpha\": 0.5}),\n",
    "    # (\"slo\", 2.0, \"test\", {\"color\": \"tab:green\", \"alpha\": 1.0}),\n",
    "    # (\"por\", 2.0, \"test\", {\"color\": \"tab:red\", \"alpha\": 0.5}),\n",
    "    # (\"por\", 3.0, \"test\", {\"color\": \"tab:red\", \"alpha\": 1.0}),\n",
    "]:    \n",
    "    print(f\"Split: {split}, {cohort}/{version}\")\n",
    "    data_subset = filter_by_metadata(data, cohort=cohort, version=version, split=split)\n",
    "    \n",
    "    y_true = data_subset[Y_COLUMN]\n",
    "    y_pred = model.predict_proba(data_subset[X_COLUMNS])[:, 1]\n",
    "\n",
    "    display = PrecisionRecallDisplay.from_predictions(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        name=f\"{split}, {cohort}/{version}\",\n",
    "        plot_chance_level=False,\n",
    "        drop_intermediate=True,\n",
    "        ax=ax,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bdbc8-c371-444f-ab49-471bbad5aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import model_fn\n",
    "from inference import preprocess_sample\n",
    "\n",
    "def check_dicts_close(a: dict, b: dict, tol: float = 1e-4) -> None:\n",
    "    assert set(a) == set(b)\n",
    "    for key in a:\n",
    "        assert type(a[key]) is type(b[key]), (key, a[key], b[key])\n",
    "        if isinstance(a[key], float):\n",
    "            assert abs(a[key] - b[key]) < tol, (key, a[key], b[key])\n",
    "        else:\n",
    "            assert a[key] == b[key], (key, a[key], b[key])\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "for sample_id in data_raw.index:\n",
    "    sample_raw = json.loads(data_raw.loc[sample_id, X_COLUMN_ORDER].to_json())\n",
    "\n",
    "    sample = preprocess_sample(sample_raw, debug=debug)\n",
    "    expected_sample = data.loc[sample_id, X_COLUMNS].to_dict()\n",
    "    for feature_name_bin in BINARY_CATEGORICAL_COLUMNS:\n",
    "        expected_sample[feature_name_bin] = float(expected_sample[feature_name_bin])\n",
    "    \n",
    "    if debug:\n",
    "        print(json.dumps(expected_sample, indent=4))\n",
    "\n",
    "    check_dicts_close(sample, expected_sample)\n",
    "\n",
    "    probability = model_fn(sample)\n",
    "    expected_probability = float(model.predict_proba(data.loc[[sample_id], X_COLUMNS])[0, 1])\n",
    "    \n",
    "    assert abs(probability - expected_probability) < 1e-04, (probability, expected_probability)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963fa78-9d55-4804-99ec-842c30f9b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "\n",
    "WEIGHTS = {\n",
    "    feature_name: float(weight)\n",
    "    for feature_name, weight in zip(\n",
    "        model.feature_names_in_, model.coef_[0]\n",
    "    )\n",
    "}\n",
    "INTERCEPT = float(model.intercept_[0])\n",
    "\n",
    "print(INTERCEPT)\n",
    "print(json.dumps(WEIGHTS, indent=4))\n",
    "print(json.dumps(scaling_info, indent=4))\n",
    "\n",
    "BINARY_CATEGORICAL_COLUMNS = [\n",
    "    \"gender\",  # 2\n",
    "    \"fh_xant\",  # 2\n",
    "    \"fh_acrus_senilis\",  # 2\n",
    "    # \"gen_conf_fh\",  # 2\n",
    "]\n",
    "MULTI_CATEGORICAL_COLUMNS = [\n",
    "    \"fh_high_cholesterol\",  # 4\n",
    "    \"fh_premature_cad\",  # 4\n",
    "    \"fh_pad_cvi\",  # 4\n",
    "]\n",
    "\n",
    "\n",
    "INTERCEPT = -8.330929160368113\n",
    "WEIGHTS = {\n",
    "    \"age\": 0.00667784927430266,\n",
    "    \"gender\": 0.32143804346854776,\n",
    "    \"fh_high_cholesterol_1\": 0.34873544396742856,\n",
    "    \"fh_high_cholesterol_2\": 0.02078297866340733,\n",
    "    \"fh_high_cholesterol_3\": 0.643902650173691,\n",
    "    \"fh_premature_cad_1\": 0.05226457867177578,\n",
    "    \"fh_premature_cad_2\": 0.12812175064921372,\n",
    "    \"fh_premature_cad_3\": 0.03427669157864839,\n",
    "    \"fh_pad_cvi_1\": 0.02237060945544122,\n",
    "    \"fh_pad_cvi_2\": -0.364993539338868,\n",
    "    \"fh_pad_cvi_3\": 0.00978393164164006,\n",
    "    \"fh_xant\": -0.21087954347939916,\n",
    "    \"fh_acrus_senilis\": 0.2413157398789852,\n",
    "    \"hdl_cholesterol\": -0.8760712481075249,\n",
    "    \"ldl_cholesterol\": 1.3552895085240824,\n",
    "    \"total_cholesterol\": 1.1470281822853394,\n",
    "    \"tag\": -0.5361077381018685,\n",
    "    \"bmi_z_score\": -0.05708627050403221,\n",
    "    \"lp_a\": -0.4028915834363285\n",
    "}\n",
    "SCALING_INFO = {\n",
    "    \"age\": {\n",
    "        \"mean\": 7.314633123689728,\n",
    "        \"std\": 2.607213078684607\n",
    "    },\n",
    "    \"hdl_cholesterol\": {\n",
    "        \"mean\": 1.5362264150943397,\n",
    "        \"std\": 0.37043406815321883\n",
    "    },\n",
    "    \"ldl_cholesterol\": {\n",
    "        \"mean\": 3.78845283018868,\n",
    "        \"std\": 1.1593288141513893\n",
    "    },\n",
    "    \"total_cholesterol\": {\n",
    "        \"mean\": 5.767471698113208,\n",
    "        \"std\": 1.1603039079279096\n",
    "    },\n",
    "    \"tag\": {\n",
    "        \"mean\": 1.0961132075471698,\n",
    "        \"std\": 0.7718188209096246\n",
    "    },\n",
    "    \"bmi_z_score\": {\n",
    "        \"mean\": 0.28694020169346707,\n",
    "        \"std\": 1.3078173489609493\n",
    "    },\n",
    "    \"lp_a\": {\n",
    "        \"mean\": 310.6692307692308,\n",
    "        \"std\": 332.1171687025873\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_sample(raw_sample: dict) -> dict:\n",
    "    skip_columns = {\"cohort\", \"predicted_probability\", \"version\", \"gen_conf_fh\", \"split\"}\n",
    "    assert set(raw_sample) - skip_columns == set(X_COLUMN_ORDER)\n",
    "\n",
    "    print(json.dumps(raw_sample, indent=4))\n",
    "    \n",
    "    sample = {}\n",
    "    for feature_name, feature_value in raw_sample.items():\n",
    "        if feature_name in skip_columns:\n",
    "            continue\n",
    "        \n",
    "        if feature_name in BINARY_CATEGORICAL_COLUMNS:\n",
    "            sample[feature_name] = float(feature_value)\n",
    "        elif feature_name in MULTI_CATEGORICAL_COLUMNS:\n",
    "            assert isinstance(feature_value, int)\n",
    "            for value in [1, 2, 3]:\n",
    "                sample[f\"{feature_name}_{value}\"] = 1.0 if feature_value == value else 0.0\n",
    "        elif feature_name in scaling_info:\n",
    "            assert isinstance(feature_value, float)\n",
    "            mean = scaling_info[feature_name][\"mean\"]\n",
    "            std = scaling_info[feature_name][\"std\"]\n",
    "            sample[feature_name] = float((feature_value - mean) / std )\n",
    "        else:\n",
    "            assert False, feature_name\n",
    "\n",
    "    print(json.dumps(sample, indent=4))\n",
    "\n",
    "    assert len(set(sample) - set(X_COLUMNS)) == 0, set(sample) - set(X_COLUMNS)\n",
    "    assert len(set(X_COLUMNS) - set(sample)) == 0, set(X_COLUMNS) - set(sample)\n",
    "        \n",
    "    return sample\n",
    "\n",
    "def model_fn(sample: dict) -> float:\n",
    "    assert set(X_COLUMNS) == set(sample)\n",
    "    assert set(WEIGHTS) == set(sample)\n",
    "\n",
    "    def _sigmoid(x: float) -> float:\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    # Logistic regression\n",
    "    weighted_sum = INTERCEPT\n",
    "    for feature_name, weight_value in WEIGHTS.items():\n",
    "        feature_value = sample[feature_name]\n",
    "        weighted_sum += weight_value * feature_value\n",
    "\n",
    "    return _sigmoid(weighted_sum)\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "raw_sample = data_raw.iloc[0].to_dict()\n",
    "model_fn(preprocess_sample(raw_sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
